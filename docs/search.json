[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 Brad Blaser Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/week_1.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Week 1:  Setting Up","text":"course focus believe essential skills necessary laboratory-based scientist use R Rstudio effective way. many detailed resources . Software carpentry good tutorials R, python, git working command line. R data science book written Hadley Wickham wrote much software use R Modern dive focused modeling interested clinical data sets many others good resources want extend knowledge beyond cover . Learning R times seem like learning foreign language. make errors. Always remember never first person encounter error. Learn google error message 99% time find answer first 3 hits. learn.","code":""},{"path":"/articles/week_1.html","id":"r-and-rstudio","dir":"Articles","previous_headings":"","what":"R and Rstudio","title":"Week 1:  Setting Up","text":"R statistical programming language runs computer program. Rstudio known integrated development environment IDE. standard way humans interact R program. Rstudio provides two main ways interacting R: directly via R Console via R scripts. R console: type commands output usually returned console. commands logged history file really need , inconvenient. better option use scripts. Warning Error messages appear console. Always pay attention saying. R scripts: text files, usually form .R. run 1 lines, Rstudio feeds console R follows commands. good always plain text record . build multi-step analysis easy see got end product. Better running whole file line line “sourcing” file. can typing Ctrl+Shift+S clicking “Source” button upper right corner source pane (usually top-left) Rstudio. better? Let’s say left error script. Maybe presence error changes final output trying produce. run lines, R notify error keep going. Easy miss error. source file, stop completely errors don’t end errors aren’t aware . always want programs error obvious ways don’t carry incorrect data. Rstudio provides number standard panes display useful information. review class can explore . default, R studio gives option save workspace data close session reload workspace file next time start work. generally good idea, reasons see. wastes time loading quitting sessions want explicit objects saving, save . turn , go Rstudio menu bar, select Tools, Global Options. Make following selections pop-window: R studio workspace options","code":""},{"path":"/articles/week_1.html","id":"setting-up-your-system","dir":"Articles","previous_headings":"","what":"Setting up your system","title":"Week 1:  Setting Up","text":"recommend approach setting R installation. comparison methods, blaseRtemplates method provides greater transparency reproducibility improved user experience (faster, fewer confusing messages). First, install blaseRtemplates package using whatever package installer currently use. Assuming base install function, run: Next, simply run following command: ? create directories indicated, write standard .Rprofile document, modify user .Renviron file configure R properly. overwrite existing directories fail existing installation already present location. modification outside provided directory .Renviron file. existing configurations .Renviron file, changed conflicting. problematic, archive .Renviron file running. new .Renviron file cause R use new .Rprofile cache directory skip existing user- project-level .Rprofiles. R starts new session, looks series files configure . configuration includes environment variables (.Renviron file) desired R code (.Rprofile file). included function, configurations affect user experience .e. affect results produced code. user experience mean connection proper package libraries repositories safeguards prevent working outside projects. information R starts, see link..","code":"install.packages('blaseRtemplates', repos = c('https://blaserlab.r-universe.dev')) library(\"blaseRtemplates\") establish_new_bt(cache_path = \"<some_directory>/r_4_2_cache\", project_path = \"<some_directory>/projects\")"},{"path":"/articles/week_1.html","id":"directory-structure","dir":"Articles","previous_headings":"Setting up your system","what":"Directory Structure","title":"Week 1:  Setting Up","text":"First, note two main subdirectories created one parent directory. optional can specified function inputs, single user system recommended keep together sake organization. projects: projects initialized. can go anywhere keep . baseproject created establish_new_bt function. close project without moving new one try start session outside project, bounce . prevents undesired operations e.g. home directory elsewhere. r_4_2_cache: holds inner workings blaseRtemplates system. library: versioned/hashed package binary cache. package stored following rubric: name > version > hash > name > contents. structure generated whenever blaseRtemplates installs new package project. logs: collection .Rhistory files. Rather 1 endless file (default), blaseRtemplates store history files session user date/time source: Package source files. Used installer, pak. user_project: collection symlinks versioned/hashed packages library. identified first entry .libPaths() R looks first packages. ? 1. allows reproducibility. update package one project, may break something older project. allows project set packages. (list versions used kept tsv file within project, completely portable. Anyone wants replicate code just install list packages.) 2. makes system lightweight. Package code significantly, data, stored one location accessible many projects, according version. dependency_catalog.tsv: list package dependencies package hash. Speeds installation linking packages cache project. package_catalog.tsv: master catalog packages available cache. .Rprofile: Rprofile used startup, specified new .Renviron file library directory initially populated using packages available R local libraries. Depending libraries, processing/network speeds, may take time.","code":". |-- projects |   `-- baseproject `-- r_4_2_cache     |-- library     |-- logs     |-- source     |-- user_project     |-- dependency_catalog.tsv     |-- package_catalog.tsv     `-- .Rprofile"},{"path":"/articles/week_1.html","id":"projects","dir":"Articles","previous_headings":"","what":"Projects","title":"Week 1:  Setting Up","text":"project self-contained group files R data analysis. align conceptually experiments. set single cell data imaging data related scientific concept paper can go project. Projects automatically define working directory root projects. means can reference file root directory typing name like : “file.R”. file one directory , “directory/file.R”. almost good reason ever change working directory something project root. always want working project. Another way think project : big set scripted instructions converts data figures, tables useful documents can directly use thesis manuscript. instructions form text documents reside project. Nothing besides text-based instructions project critical instructions saved external project. want use GIT track changes instructions time GITHUB share collaborators, journal reviewers, scientific community. blaseRtemplates project structure help sensible way.","code":""},{"path":"/articles/week_1.html","id":"setting-up-a-project","dir":"Articles","previous_headings":"Projects","what":"Setting up a project","title":"Week 1:  Setting Up","text":"best way automated commands, rather program menus. way every package set consistent manner, every time. revisit project months months, easy navigate. function create skeletonized project, activate restart session within .","code":"# create a project called rclass_project_2023 in your projects directory blaseRtemplates::initialize_project(\"<projects directory>/rclass_project_2023\")"},{"path":"/articles/week_1.html","id":"project-organization","dir":"Articles","previous_headings":"Projects","what":"Project organization","title":"Week 1:  Setting Up","text":"keep R scripts directory called “R”. initialized project blaseRtemplates::initialize_project(), scripts named: initialization.R: use setting project use git github dependencies.R: use loading data attaching packages session * configs.R: use setting graphical aesthetic parameters. also use resolving function name conflicts. * git_commands.R: commands allow handle 99% git interactions via R scripted way. addition , main analysis scripts project go R folder may go subdirectories lot . file types, *.Rmd, go folder named Rmd/. arrangement flexible simple data analysis projects; rules become strict build packages.","code":""},{"path":"/articles/week_1.html","id":"git-and-github","dir":"Articles","previous_headings":"Projects","what":"Git and github","title":"Week 1:  Setting Up","text":"want try use git github. vast array resources read git troubleshoot issues. Briefly, program tracks changes text files. Since code write text-based great resource keep track progress work. Git tracks changes files group files known repository. way using , project repository. Github simply website hosts copy repository web. share work journal reviewers editors others.","code":""},{"path":"/articles/week_1.html","id":"setting-up-git-and-github-for-the-first-time-on-a-system","dir":"Articles","previous_headings":"Projects","what":"Setting up git and github for the first time on a system","title":"Week 1:  Setting Up","text":"things need connect git, github R first time. lines included bottom file, “R/git_commands.R”. start every project usually leave . Sometimes connection issues github run get new credentials. Connecting/authenticating github difficult part . keychain program used gitcreds_set() may available working systems. workaround, can replace line .Renviron file, GITHUB_PAT=gitcreds::gitcreds_get(use_cache = FALSE)$password, GITHUB_PAT=your_token. small security risk someone gain access .Renviron file. proceed caution. necessary permissions set automatically commands. default, token expires 30 days, can override usually .","code":"# make sure you have a github account # https://github.com/join  # install git ## Windows ->  https://git-scm.com/download/win ## Mac     ->  https://git-scm.com/download/mac ## Linux   ->  https://git-scm.com/download/linux  # configure git in Rstudio usethis::use_git_config(user.name = \"YourName\",                         user.email = \"your@mail.com\")  # create a personal access token at the github website # set the expiration date as desired (no expiration date) # permissions should be set automatically.   usethis::create_github_token()  # run this and enter your token at the prompt blaseRtemplates::gitcreds_set()  # Run the following once per user to collaborate smoothly blaseRtemplates::setup_git_collab()"},{"path":"/articles/week_1.html","id":"set-up-your-project-to-use-git-and-github","dir":"Articles","previous_headings":"Projects","what":"Set up your project to use git and github","title":"Week 1:  Setting Up","text":"following lines taken directly “R/initialization.R”. run start project first time: run script, can delete .","code":"# make a software license usethis::use_mit_license(\"<your name here>\")  # generate a readme file to explain your work usethis::use_readme_md(open = FALSE)  # *** Only if developing a package *** # uncomment and run to generate a news file to document updates. # usethis::use_news_md()  # initialize git usethis::use_git()  # initialize github usethis::use_github(private = TRUE)   ### Delete this file after initializing the project! ###"},{"path":"/articles/week_1.html","id":"using-git-and-github","dir":"Articles","previous_headings":"Projects","what":"Using git and github","title":"Week 1:  Setting Up","text":"can interact git least 4 different ways: via scripted commands R/git_commands.R using Git pane Rstudio using terminal using third-party git client git kraken sourcetree recommended approach use scripted git commands control happening use Git pane monitor status repository. Just remember hit refresh icon things look strange Git panel. rare occasions may need use terminal fix conflicts, happen collaborating git. Many people use third-party apps, learning curve. basic process using Git single user : save open files check status repository know files changed add Git index files commit create save point files project push commit remote repository (github) commands git_commands.R ! run problems, error messages usually informative. trouble understanding error isn’t helpful, just google . One common use-case git single user “un-delete” files. easiest way go github site repo. Click clock icon labeled “commits” (helpfully includes “back time” arrow). select list commits (versions). Click browse files find looking . Click raw version copy paste directly back R studio. ’s complicated situation us can relate : submit beautiful manuscript Journal Journal bounces right back reformat figures paper R submit Journal B Journal B interested, send review 6 weeks later reject . decide submit Journal C similar figure formatting Journal . ? Hopefully commit git log message “submitted Journal ”. select id (long character string) provide blaseRtemplates::git_rewind_to() function. function generate new commit reverses changes present, back indicated commit. Nothing lost overwritten process going back time. thing happens inverse changes applied. need go Journal D (formatted like Journal B) can always later.","code":"# basic everyday commands for all git users -------------------------------   gert::git_status() gert::git_add(\"*\") gert::git_commit(\"a short comment describing the changes made\") blaseRtemplates::git_push_all() # run these commands to rewind to a prior \"good\" commit ----------------------  # make sure git status is \"clean\" (all changes committed) before rewinding # gert::git_log() #find the id of the good commit # blaseRtemplates::git_rewind_to(commit = \"<good commit id>\")"},{"path":"/articles/week_1.html","id":"packages","dir":"Articles","previous_headings":"","what":"Packages","title":"Week 1:  Setting Up","text":"Packages chunks code /data people written made available us use. main reason use R large library useful packages biological sciences can build work , free use. Packages often stored distributed via standard repositories. common CRAN, R-universe, Bioconductor. Packages can also distributed source code (text based files), usually via github. happens “install” packages? R downloads compressed file unpacks library directory computer server. installing source code (linux computers github repositories), code needs turned set binary instructions computer use, process called compiling. Xcode (Mac) RTools (Win) programs . Every time start R session, set commands run points R one library directories. R finds commands ask use. Unfortunately, can difficult find directories live, depending installation. BlaseRtemplates helps manage . use function? installed package, functions available called using package name followed 2 colons dplyr::filter(mtcars, cyl == 6). always best way go. make functions package available, need run library(\"<package name>\"). attach functions package session. can just use function name without package prefix. Beware attaching packages actually need though “namespace conflicts”. happens term applies two different functions two different packages. R picks one goes without clearly indicating . common source errors. Later see use “conflicted” package help warn us errors cause problem. look help R functions? manual function R package generated can viewed help panel RStudio. Access ?<object name> e.g. ?mean. Vignettes may also available. Vignettes long-form articles show use functions package together, often example data. best accessed navigating package menu. Click package name near top see available vignettes.","code":""},{"path":"/articles/week_1.html","id":"installing-packages","dir":"Articles","previous_headings":"Packages","what":"Installing packages","title":"Week 1:  Setting Up","text":"mentioned , blaseRtemplates-based projects use user-project library linked specific package versions main cache. way, project start can use set packages without duplication actual software. Also, update package project B, doesn’t update package project . good? unintentional updates may “break” older project something want avoid. best way install packages using blaseRtemplates : Install new package get latest version repository Get fresh link newest version available cache Get specific version cache Versioned package installations supported cran . unavailable, latest version installed. can find human-readable table packages cache BLASERTEMPLATES_CACHE_ROOT/package_catalog.tsv. package cache “hashed”. means even two different versions package share version number, can still tell apart install one need. shouldn’t happen can someone updates package forgets increment version number. Install specific hash package can find human-readable table packages used given project library_catalogs directory project. least one file . projects collaborating git, one user. files indicate available actively used packages R code. file meant tracked git can provide version control reproducibility packages used project. collaborator getting different results errors, can use see exactly package set working .","code":"blaseRtemplates::install_one_package(package = \"<package_name>\", how = \"new_or_update\") blaseRtemplates::install_one_package(package = \"<package_name>\", how = \"link_from_cache\") blaseRtemplates::install_one_package(package = \"<package_name>\", how = \"link_from_cache\", which_version = \"1.0.0\") blaseRtemplates::install_one_package(package = \"<cran_package_name>\", how = \"new_or_update\", which_version = \"1.0.0\") blaseRtemplates::install_one_package(package = \"<cran_package_name>\", how = \"new_or_update\", which_hash = \"72f8712f97416089ade12df29386b80b\")"},{"path":"/articles/week_1.html","id":"get-a-new-project-library","dir":"Articles","previous_headings":"Packages","what":"Get a new project library","title":"Week 1:  Setting Up","text":"can use function replace entire project library new one. default, function install newest version package available available cache. Say, however, want adopt entire package library used collaborator project (one past self, retrieved git), supply project library catalog argument get_new_library().","code":"blaseRtemplates::get_new_library() blaseRtemplates::get_new_library(\"library_catalogs/<file>.tsv\")"},{"path":"/articles/week_1.html","id":"exercises","dir":"Articles","previous_headings":"","what":"Exercises","title":"Week 1:  Setting Up","text":"Use code blocks vignette make new R project system extra credit push github. First, establish blaseRtemplates installation Next create new project Connect system github account using git_commands.R script Last, run initialization script delete Explore scripts R directory. Try running code dependencies.R install recommended packages. Save work, add, commit, push github site.","code":""},{"path":"/articles/week_2.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Week 2:  R Fundamentals","text":"Today discuss fundamentals working data R. always one way accomplish task reading, analyzing plotting data. perspective accomplished computer code easy read error-resistant. opinion, “tidyverse” family packages achieve goal moreso “base” R functions packages large percentage time. mostly show tidyverse way.","code":""},{"path":"/articles/week_2.html","id":"data-formatting","dir":"Articles","previous_headings":"","what":"Data formatting","title":"Week 2:  R Fundamentals","text":"best way make coding easy start formatting data proper way. theory interested. short data : flat text file format, .csv (comma separated values), .tsv (tab separated values) .txt (plain text). file extensions don’t matter R; affect program reads file mac PC. Unlike excel files, files can tracked git know changes made accidentally. row represents observation column represents variable attribute observation column single specific “type”: numeric, integer, factor character common types use row unique “key”. key can single column combination columns long distinguishes row every row.","code":""},{"path":"/articles/week_2.html","id":"input-and-data-types","dir":"Articles","previous_headings":"","what":"Input and data types","title":"Week 2:  R Fundamentals","text":"Data exist fixed, unchanging file hard drive. want read R using readr::read_csv(). tidyverse command reads file, automatically infers data types, formats data “tibble”. tibble related dataframe base R superior characteristics almost everything . Think programmatic representation csv file within R. data collection sample datasets provided R. provided, lacks useful “key” column, added observation column first position. data indicate measurements various species iris flower. read R, read_csv command infers data types values provided provides message explaining done. case, correct except observation. ? interpreted observation “dbl” another way saying “numeric” case really correct. Observation just serial number observations case inherent order quantitative value. can tell R interpret factor R data type ordered data. string “fddddc” tells R interpret columns “factor”, “double” “character”. always check data types correct import data order prevent errors.","code":"# attach the packages we will need library(\"tidyverse\") # read in an example data file # or substitute a file path to your own data readr::read_csv(file = \"https://raw.githubusercontent.com/blaserlab/datascience.curriculum/main/inst/extdata/demo_iris_data.csv\") #> # A tibble: 150 × 6 #>    observation Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>          <dbl>        <dbl>       <dbl>        <dbl>       <dbl> <chr>   #>  1           1          5.1         3.5          1.4         0.2 setosa  #>  2           2          4.9         3            1.4         0.2 setosa  #>  3           3          4.7         3.2          1.3         0.2 setosa  #>  4           4          4.6         3.1          1.5         0.2 setosa  #>  5           5          5           3.6          1.4         0.2 setosa  #>  6           6          5.4         3.9          1.7         0.4 setosa  #>  7           7          4.6         3.4          1.4         0.3 setosa  #>  8           8          5           3.4          1.5         0.2 setosa  #>  9           9          4.4         2.9          1.4         0.2 setosa  #> 10          10          4.9         3.1          1.5         0.1 setosa  #> # … with 140 more rows readr::read_csv(file = \"https://raw.githubusercontent.com/blaserlab/datascience.curriculum/main/inst/extdata/demo_iris_data.csv\", col_types = \"fddddc\") #> # A tibble: 150 × 6 #>    observation Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>    <fct>              <dbl>       <dbl>        <dbl>       <dbl> <chr>   #>  1 1                    5.1         3.5          1.4         0.2 setosa  #>  2 2                    4.9         3            1.4         0.2 setosa  #>  3 3                    4.7         3.2          1.3         0.2 setosa  #>  4 4                    4.6         3.1          1.5         0.2 setosa  #>  5 5                    5           3.6          1.4         0.2 setosa  #>  6 6                    5.4         3.9          1.7         0.4 setosa  #>  7 7                    4.6         3.4          1.4         0.3 setosa  #>  8 8                    5           3.4          1.5         0.2 setosa  #>  9 9                    4.4         2.9          1.4         0.2 setosa  #> 10 10                   4.9         3.1          1.5         0.1 setosa  #> # … with 140 more rows"},{"path":"/articles/week_2.html","id":"more-on-data-types","dir":"Articles","previous_headings":"Input and data types","what":"More on data types","title":"Week 2:  R Fundamentals","text":"character: string valid alphanumeric characters. Carries order quantitative value besides “alphanumeric” order numeric/double: real number integer: integer, subset real numbers factor: factors essentially characters bound integer values. character part called “level”. Factors can little tricky useful ordering reordering categorical data.","code":""},{"path":"/articles/week_2.html","id":"variable-assignment","dir":"Articles","previous_headings":"","what":"Variable assignment","title":"Week 2:  R Fundamentals","text":"important advantage using programming language analyze data concept abstraction, assigning complicated values simple variable names. left arrow operator stores data global environment name “demo_data”. valid R object (data, functions etc) can stored variable name. default stored global environment. global environment “workspace” every value save held memory. save something else name environment overwrite old value without checking, asking notifying .","code":"# assign the data to the variable, demo_data # readr::read_csv(file = system.file(\"extdata/demo_iris_data.csv\", package = \"datascience.curriculum\")) demo_data <- readr::read_csv(file = \"https://raw.githubusercontent.com/blaserlab/datascience.curriculum/main/inst/extdata/demo_iris_data.csv\", col_types = \"fddddc\") demo_data #> # A tibble: 150 × 6 #>    observation Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>    <fct>              <dbl>       <dbl>        <dbl>       <dbl> <chr>   #>  1 1                    5.1         3.5          1.4         0.2 setosa  #>  2 2                    4.9         3            1.4         0.2 setosa  #>  3 3                    4.7         3.2          1.3         0.2 setosa  #>  4 4                    4.6         3.1          1.5         0.2 setosa  #>  5 5                    5           3.6          1.4         0.2 setosa  #>  6 6                    5.4         3.9          1.7         0.4 setosa  #>  7 7                    4.6         3.4          1.4         0.3 setosa  #>  8 8                    5           3.4          1.5         0.2 setosa  #>  9 9                    4.4         2.9          1.4         0.2 setosa  #> 10 10                   4.9         3.1          1.5         0.1 setosa  #> # … with 140 more rows"},{"path":"/articles/week_2.html","id":"data-structures","dir":"Articles","previous_headings":"","what":"Data structures","title":"Week 2:  R Fundamentals","text":"Dataframes tibbles essentially lists vectors rules attached. lists vectors? vector fundamental data structure R. collection data values, must data type. can make vector directly R like : dataframe tibble, column vector. can use R operators extract columns vectors. Usually want use $ operator extract column name. list general form data object. can hold combination R data types. make list: Lists flexible useful objects holding data.","code":"# a numeric vector c(1, 2, 3) #> [1] 1 2 3  # a character vector c(\"a\", \"b\", \"c\") #> [1] \"a\" \"b\" \"c\"  # another character vector c(\"1\", \"b\" ,\"charlie\") #> [1] \"1\"       \"b\"       \"charlie\"  # here 1 gets coerced to a character because a vector must be all the same type c(1, \"b\", \"charlie\") #> [1] \"1\"       \"b\"       \"charlie\" # extract a column by position # the head command prints the first few values only # omit head() if you want the whole thing head(demo_data[[2]]) #> [1] 5.1 4.9 4.7 4.6 5.0 5.4  # extract a column by name head(demo_data[[\"Species\"]]) #> [1] \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\"  # another way to extract a column by name head(demo_data$Species) #> [1] \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" # make the list demo_list <- list(1, \"b\", \"charlie\")  demo_list #> [[1]] #> [1] 1 #>  #> [[2]] #> [1] \"b\" #>  #> [[3]] #> [1] \"charlie\"  # optionally name the elements names(demo_list) <- c(\"a_number\", \"a_letter\", \"a_name\")  # extract the elements by name demo_list$a_number #> [1] 1 demo_list$a_letter #> [1] \"b\" demo_list$a_name #> [1] \"charlie\""},{"path":"/articles/week_2.html","id":"subsetting-with-base-r-functions","dir":"Articles","previous_headings":"","what":"Subsetting with base R functions","title":"Week 2:  R Fundamentals","text":"think syntax suboptimal compared Dplyr syntax, advanced data objects need know . subsetting use single bracket rather double bracket extracting data. returns object class, smaller.","code":"# subset using dataframe[row,colum] syntax # subset a dataframe to get the second and third columns only demo_data[,2:3] #> # A tibble: 150 × 2 #>    Sepal.Length Sepal.Width #>           <dbl>       <dbl> #>  1          5.1         3.5 #>  2          4.9         3   #>  3          4.7         3.2 #>  4          4.6         3.1 #>  5          5           3.6 #>  6          5.4         3.9 #>  7          4.6         3.4 #>  8          5           3.4 #>  9          4.4         2.9 #> 10          4.9         3.1 #> # … with 140 more rows  # subset a dataframe to get the first and second rows only demo_data[1:2,] #> # A tibble: 2 × 6 #>   observation Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>   <fct>              <dbl>       <dbl>        <dbl>       <dbl> <chr>   #> 1 1                    5.1         3.5          1.4         0.2 setosa  #> 2 2                    4.9         3            1.4         0.2 setosa  # subset to include columns by name  demo_data[c(\"Species\", \"observation\")] #> # A tibble: 150 × 2 #>    Species observation #>    <chr>   <fct>       #>  1 setosa  1           #>  2 setosa  2           #>  3 setosa  3           #>  4 setosa  4           #>  5 setosa  5           #>  6 setosa  6           #>  7 setosa  7           #>  8 setosa  8           #>  9 setosa  9           #> 10 setosa  10          #> # … with 140 more rows  # subset a list to return a smaller list # return the first two elements demo_list[1:2] #> $a_number #> [1] 1 #>  #> $a_letter #> [1] \"b\"  # subset a list by name demo_list[\"a_name\"] #> $a_name #> [1] \"charlie\""},{"path":"/articles/week_2.html","id":"data-operations","dir":"Articles","previous_headings":"","what":"Data operations","title":"Week 2:  R Fundamentals","text":"R fundamental data structure vector. single value vector length 1. Many functions optimized work entire vector . can read arithmetic logical operators . Logical operators return value TRUE FALSE.","code":"# get the mean of the sepal length mean(demo_data$Sepal.Length) #> [1] 5.843333  # add two vectors c(1, 2) + c(2, 3) #> [1] 3 5  # for vectors of unequal length, the smaller vector is \"recycled\" for each element of the larger vector 1 + c(1, 2, 3) #> [1] 2 3 4  # this gives a warning if the recycling doesn't work out evenly c(1, 2) + c(1, 2, 3) #> Warning in c(1, 2) + c(1, 2, 3): longer object length is not a multiple of #> shorter object length #> [1] 2 4 4 1 > 0 #> [1] TRUE  2 == 2 #> [1] TRUE  1 != 3 #> [1] TRUE  2 <= 1 #> [1] FALSE  \"apple\" == \"banana\" #> [1] FALSE"},{"path":"/articles/week_2.html","id":"dplyr","dir":"Articles","previous_headings":"","what":"Dplyr","title":"Week 2:  R Fundamentals","text":"Dplyr part tidyverse packages. use data transformations prior statistical testing plotting. Dplyr functions pipe-friendly, meaning can chained way reduces redundant text code saving intermediate values can cause problems. use pipe operator |>. Dplyr functions also vectorized computationally efficient can used tables hundreds thousands rows. can use built-custom function mutate summarise. Functions mutate must return vector length input vector; functions summarise must return vector length 1. Sometimes may find useful select de-select columns tibble: Use filter select rows based conditional test(s): cases may useful data “long form” opposed “wide form”. use pivot_longer going tell R columns convert long form. type end column. selected column names get repeated “name” column values end “value” column. columns don’t select retained additional attributes values. Sometimes two tibbles related information want join together. powerful tool adding new attributes onto existing data. rules joining: must least 1 column common values join . better 1 1. easiest way make sure column name tables. avoid duplicated values either tables want join. Usually want keep “main” data table add new data. new data duplicate entries duplicated output may cause problems. missing data filled NA usually OK. order data two tables doesn’t matter. left_join(x, y) order data resulting tibble x exception possible duplications. always check sure join worked OK information operations see useful cheat sheet.","code":"# add a new column with mutate # then group by a useful categorical variable # then summarize the new value we calculated by mean according to group demo_data |>   mutate(sepal_l_w = Sepal.Length + Sepal.Width) |>   group_by(Species) |>   summarise(mean_sepal_l_w = mean(sepal_l_w)) #> # A tibble: 3 × 2 #>   Species    mean_sepal_l_w #>   <chr>               <dbl> #> 1 setosa               8.43 #> 2 versicolor           8.71 #> 3 virginica            9.56 # return a tibble without the observation column demo_data |>   select(-observation) #> # A tibble: 150 × 5 #>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>           <dbl>       <dbl>        <dbl>       <dbl> <chr>   #>  1          5.1         3.5          1.4         0.2 setosa  #>  2          4.9         3            1.4         0.2 setosa  #>  3          4.7         3.2          1.3         0.2 setosa  #>  4          4.6         3.1          1.5         0.2 setosa  #>  5          5           3.6          1.4         0.2 setosa  #>  6          5.4         3.9          1.7         0.4 setosa  #>  7          4.6         3.4          1.4         0.3 setosa  #>  8          5           3.4          1.5         0.2 setosa  #>  9          4.4         2.9          1.4         0.2 setosa  #> 10          4.9         3.1          1.5         0.1 setosa  #> # … with 140 more rows # return a tibble with only the Species and Sepal.Length columns demo_data |>   select(c(Species, Sepal.Length)) #> # A tibble: 150 × 2 #>    Species Sepal.Length #>    <chr>          <dbl> #>  1 setosa           5.1 #>  2 setosa           4.9 #>  3 setosa           4.7 #>  4 setosa           4.6 #>  5 setosa           5   #>  6 setosa           5.4 #>  7 setosa           4.6 #>  8 setosa           5   #>  9 setosa           4.4 #> 10 setosa           4.9 #> # … with 140 more rows # filter rows satisfying a logical test demo_data |>   filter(Species == \"setosa\") #> # A tibble: 50 × 6 #>    observation Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>    <fct>              <dbl>       <dbl>        <dbl>       <dbl> <chr>   #>  1 1                    5.1         3.5          1.4         0.2 setosa  #>  2 2                    4.9         3            1.4         0.2 setosa  #>  3 3                    4.7         3.2          1.3         0.2 setosa  #>  4 4                    4.6         3.1          1.5         0.2 setosa  #>  5 5                    5           3.6          1.4         0.2 setosa  #>  6 6                    5.4         3.9          1.7         0.4 setosa  #>  7 7                    4.6         3.4          1.4         0.3 setosa  #>  8 8                    5           3.4          1.5         0.2 setosa  #>  9 9                    4.4         2.9          1.4         0.2 setosa  #> 10 10                   4.9         3.1          1.5         0.1 setosa  #> # … with 40 more rows  demo_data |>   filter(Species %in% c(\"setosa\", \"versicolor\")) #> # A tibble: 100 × 6 #>    observation Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>    <fct>              <dbl>       <dbl>        <dbl>       <dbl> <chr>   #>  1 1                    5.1         3.5          1.4         0.2 setosa  #>  2 2                    4.9         3            1.4         0.2 setosa  #>  3 3                    4.7         3.2          1.3         0.2 setosa  #>  4 4                    4.6         3.1          1.5         0.2 setosa  #>  5 5                    5           3.6          1.4         0.2 setosa  #>  6 6                    5.4         3.9          1.7         0.4 setosa  #>  7 7                    4.6         3.4          1.4         0.3 setosa  #>  8 8                    5           3.4          1.5         0.2 setosa  #>  9 9                    4.4         2.9          1.4         0.2 setosa  #> 10 10                   4.9         3.1          1.5         0.1 setosa  #> # … with 90 more rows # pivot from wide form to long form long_data <- demo_data |>   pivot_longer(cols = c(Sepal.Length,  Sepal.Width, Petal.Length, Petal.Width)) long_data #> # A tibble: 600 × 4 #>    observation Species name         value #>    <fct>       <chr>   <chr>        <dbl> #>  1 1           setosa  Sepal.Length   5.1 #>  2 1           setosa  Sepal.Width    3.5 #>  3 1           setosa  Petal.Length   1.4 #>  4 1           setosa  Petal.Width    0.2 #>  5 2           setosa  Sepal.Length   4.9 #>  6 2           setosa  Sepal.Width    3   #>  7 2           setosa  Petal.Length   1.4 #>  8 2           setosa  Petal.Width    0.2 #>  9 3           setosa  Sepal.Length   4.7 #> 10 3           setosa  Sepal.Width    3.2 #> # … with 590 more rows  # pivot back to wide form long_data |>   pivot_wider(names_from = \"name\", values_from = \"value\") #> # A tibble: 150 × 6 #>    observation Species Sepal.Length Sepal.Width Petal.Length Petal.Width #>    <fct>       <chr>          <dbl>       <dbl>        <dbl>       <dbl> #>  1 1           setosa           5.1         3.5          1.4         0.2 #>  2 2           setosa           4.9         3            1.4         0.2 #>  3 3           setosa           4.7         3.2          1.3         0.2 #>  4 4           setosa           4.6         3.1          1.5         0.2 #>  5 5           setosa           5           3.6          1.4         0.2 #>  6 6           setosa           5.4         3.9          1.7         0.4 #>  7 7           setosa           4.6         3.4          1.4         0.3 #>  8 8           setosa           5           3.4          1.5         0.2 #>  9 9           setosa           4.4         2.9          1.4         0.2 #> 10 10          setosa           4.9         3.1          1.5         0.1 #> # … with 140 more rows # make two smaller tables sepal_data <-   demo_data |>   group_by(Species) |>   summarise(mean_sepal_l = mean(Sepal.Length), mean_sepal_w = mean(Sepal.Width)) sepal_data #> # A tibble: 3 × 3 #>   Species    mean_sepal_l mean_sepal_w #>   <chr>             <dbl>        <dbl> #> 1 setosa             5.01         3.43 #> 2 versicolor         5.94         2.77 #> 3 virginica          6.59         2.97  petal_data <-   demo_data |>   group_by(Species) |>   summarise(mean_petal_l = mean(Petal.Length), mean_petal_w = mean(Petal.Width)) petal_data #> # A tibble: 3 × 3 #>   Species    mean_petal_l mean_petal_w #>   <chr>             <dbl>        <dbl> #> 1 setosa             1.46        0.246 #> 2 versicolor         4.26        1.33  #> 3 virginica          5.55        2.03  # now join them back together left_join(sepal_data, petal_data) #> # A tibble: 3 × 5 #>   Species    mean_sepal_l mean_sepal_w mean_petal_l mean_petal_w #>   <chr>             <dbl>        <dbl>        <dbl>        <dbl> #> 1 setosa             5.01         3.43         1.46        0.246 #> 2 versicolor         5.94         2.77         4.26        1.33  #> 3 virginica          6.59         2.97         5.55        2.03"},{"path":"/articles/week_2.html","id":"exercises","dir":"Articles","previous_headings":"","what":"Exercises","title":"Week 2:  R Fundamentals","text":"try running example code project hint: can upload directly R studio using -arrow icon files tab explore different data manipulations base R dplyr functions hint: just need feed numeric vectors data functions.","code":""},{"path":"/articles/week_3.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Week 3:  Next Level R","text":"lecture introduces advanced concepts R. level comfort basic data types structures assign values variables. learn ways R can automate complex repetitive tasks way error-resistant.","code":""},{"path":"/articles/week_3.html","id":"scope","dir":"Articles","previous_headings":"","what":"Scope","title":"Week 3:  Next Level R","text":"Scope concept computer science names values variables relate . refers part program name variable representing piece data function valid. function piece data global environment name different function piece data certain package, R decide referring put name code. case, global environment takes priority. let’s say early analysis script choose represent piece data variable name x. probably wise choice, since x commonly used name. Maybe later script represent different piece data variable name x. overwrites old version created scope, .e. global environment. Finally want use x make error didn’t realize referred twice analysis script. ways protect : use pipes avoid saving intermediate values (see previous lecture) use unique informative variable names things must save use functional programming techniques (lecture) package processed data (subsequent lecture) R default, functions scope, meaning create special transient environment store names values variables affect global environment. values can passed arguments function can created internally. function complete, environment goes away. function environment highest priority environment function therefore first place R looks values. value variable body function isn’t found goes level scope, usually global environment (environment enclosing function). behavior error-prone try avoid . specifying external variables function needs arguments, force function stay within scope safer way go. Using functional programming practices like safe way prevent unrecognized errors analysis code.","code":""},{"path":"/articles/week_3.html","id":"writing-custom-functions","dir":"Articles","previous_headings":"","what":"Writing custom functions","title":"Week 3:  Next Level R","text":"Functions expressions code usually take input values return output values. Output returned console can assigned new variable. Functions names can behave much like objects R. can operated functions see later. Functions can also side effects, meaning can produce graphics write files separate main outputs. syntax must use writing functions R: names demonstration ; always pick names explicit clear. syntactic shortcuts can make writing calling functions, clearest best way go. order demonstrate concept scope previous section, see example: always want explicitly pass arguments functions explicitly return results shown good_sum. design, functions can return single value (although can produce number side effects). OK wanted return one object, put list return list: don’t provide names return list many cases helpful. can notice used x represent argument function. Since private variable used within scope function free time want context global environment.","code":"# simple function to add two numbers function_name <- function(argument_1, argument_2) {   result <- argument_1 + argument_2   return(result) }  function_name(argument_1 = 1, argument_2 = 2) #> [1] 3 # both arguments will be contained within the function's scope good_sum <- function(addend_1, addend_2) {   result <- addend_1 + addend_2   return(result) }  good_sum(addend_1 = 1, addend_2 = 2)  #> [1] 3  # addend_1 provided in the global environment which is inherited by the function bad_sum <- function(addend_2) {   result <- addend_1 + addend_2   return(result) }  addend_1 <- 2 bad_sum(addend_2 = 2) #> [1] 4  # the function's scope supersedes the global environment good_sum(addend_1 = 3, addend_2 = 2) #> [1] 5 two_averages <- function(x) {   # calculate the mean and median   mean <- mean(x)   median <- median(x)   # put all of the results we want into a list   return_list <- list(mean, median)   # optionally provide names to the list elements so we know exactly what they are   names(return_list) <- c(\"the_mean\", \"the_median\")   return(return_list) }   two_averages(x = c(1, 2, 3, 4, 5.5)) #> $the_mean #> [1] 3.1 #>  #> $the_median #> [1] 3"},{"path":"/articles/week_3.html","id":"conditionals","dir":"Articles","previous_headings":"","what":"Conditionals","title":"Week 3:  Next Level R","text":"Conditional statements (//else) particularly useful inside custom functions. Use provide logic function catch errors.","code":"unsafe_divide <- function(x, y) {   result <- x/y   return(result) }  # returns Infinity which is not a useful value unsafe_divide(x = 1, y = 0) #> [1] Inf  safe_divide <- function(x, y) {   if (y == 0) {     result <- \"You can't divide by 0\"   } else {     result <- x/y   }   return(result) }  safe_divide(x = 1, y = 0) #> [1] \"You can't divide by 0\""},{"path":"/articles/week_3.html","id":"mapapply","dir":"Articles","previous_headings":"","what":"Map/Apply","title":"Week 3:  Next Level R","text":"never repeat performing analysis. Copy/pasting code error prone. better encode method computer repetition. mechanisms . may familiar loops. won’t discussing number disadvantages, one tend operate global environment can cause scope issues discussed . best mechanism iterative procedure use “map” paradigm. prefer use tidyverse implementation , purrr package. provide vector list values want iteratively apply function . syntactic shortcuts confusing generally avoided, even simple examples write like . first examples much easily (quickly) accomplished vectorized math. can see, things can get complicated point may want write custom function create output want. map family number variants return result form vectors dataframes, depending output .","code":"# attach the packages we will need library(tidyverse)  # return the results in the form of a list map(   .x = c(1, 2, 3),   .f = function(x) {     result <- x + 1     return(result)   } ) #> [[1]] #> [1] 2 #>  #> [[2]] #> [1] 3 #>  #> [[3]] #> [1] 4  # return a numeric vector instead map_dbl(   .x = c(1, 2, 3),   .f = function(x) {     result <- x + 1     return(result)   } ) #> [1] 2 3 4   # map along two vectors map2(   .x = c(1, 2, 3),   .y = c(\"The first result is \",          \"The second result is \",          \"The final result is \"),   .f = function(x, y) {     result <- x + 1     return(paste0(y, result))   } ) #> [[1]] #> [1] \"The first result is 2\" #>  #> [[2]] #> [1] \"The second result is 3\" #>  #> [[3]] #> [1] \"The final result is 4\"  # map along an arbitrary number of lists or vectors  pmap(   .l = list(     x = c(1, 2, 3),     begin_text = c(\"The first result is \",           \"The second result is \",           \"The final result is \"),     end_text = c(\" apples\", \" bananas\", \" cherries\")   ),   .f = function(x, begin_text, end_text) {     result <- x + 1     return(paste0(begin_text, result, end_text))   } ) #> [[1]] #> [1] \"The first result is 2 apples\" #>  #> [[2]] #> [1] \"The second result is 3 bananas\" #>  #> [[3]] #> [1] \"The final result is 4 cherries\""},{"path":"/articles/week_3.html","id":"plotting","dir":"Articles","previous_headings":"","what":"Plotting","title":"Week 3:  Next Level R","text":"Plotting results major feature sciences. principles effective visual representation data. many resources use effectively presenting data R. Generally though want start making graphics look like look high-quality publication. Google best way find make plot R. may able get comparable results interactive program like GraphPad Excel. R let work programmatic way (letting computer work ), greater control, better aesthetics. Eventually able make sophisticated graphics possible programs. purpose lecture tell aesthetically best rather teach control aesthetics plots making suit circumstances.","code":""},{"path":"/articles/week_3.html","id":"plot-framework","dir":"Articles","previous_headings":"","what":"Plot framework","title":"Week 3:  Next Level R","text":"program use plotting data R ggplot2. start ggplot providing data mapping dimensions data aesthetics. generates “framework” plot add layers. layer adds changes visual output plot. context, one aesthetic used describe one dimension data. Common aesthetics include x y represent position space plot. Others include color, fill, size, shape, alpha (transparency) label (text label), can used describe dimensions data. simple example:  framework. X Y correctly mapped dimensions data, haven’t told ggplot display . Graphical elements called geoms:  Jitter nice geom use reduces overplotting. Although necessary plot isolation, maybe want Species depicted different color align graphical theme figure.  journals want show measure central tendency variation like mean +/- sem.  Often want nice p value indicators. tedious add R directly use helper function ggpubr package:  can change default colors using custom scales:  can look nice, visually distinct color palettes using color brewer. can also set custom scales:  Finally can change look axes, labels legends. many different lines code can use , start theme(). usually prefer start preset theme looks nice almost plots. can also get rid legend doesn’t help much case:  Keeping plot functions organized way good idea can quickly go back change things necessary.","code":"# example data as_tibble(iris) #> # A tibble: 150 × 5 #>    Sepal.Length Sepal.Width Petal.Length Petal.Width Species #>           <dbl>       <dbl>        <dbl>       <dbl> <fct>   #>  1          5.1         3.5          1.4         0.2 setosa  #>  2          4.9         3            1.4         0.2 setosa  #>  3          4.7         3.2          1.3         0.2 setosa  #>  4          4.6         3.1          1.5         0.2 setosa  #>  5          5           3.6          1.4         0.2 setosa  #>  6          5.4         3.9          1.7         0.4 setosa  #>  7          4.6         3.4          1.4         0.3 setosa  #>  8          5           3.4          1.5         0.2 setosa  #>  9          4.4         2.9          1.4         0.2 setosa  #> 10          4.9         3.1          1.5         0.1 setosa  #> # … with 140 more rows  # make the plot framework ggplot(data = iris, mapping = aes(x = Species, y = Sepal.Length)) # add a basic geom ggplot(data = iris, mapping = aes(x = Species, y = Sepal.Length)) +   geom_jitter() ggplot(data = iris, mapping = aes(x = Species, y = Sepal.Length, color = Species, fill = Species)) +   geom_jitter(shape = 21, alpha = 0.4, size = 2) ggplot(data = iris, mapping = aes(x = Species, y = Sepal.Length, color = Species, fill = Species)) +   geom_jitter(shape = 21, alpha = 0.4, size = 2) +   stat_summary(fun.data = mean_se,                 geom = \"crossbar\",                 color = \"black\",                 alpha = 0.2) library(ggpubr) ggplot(data = iris, mapping = aes(x = Species, y = Sepal.Length, color = Species, fill = Species)) +   geom_jitter(shape = 21, alpha = 0.4, size = 2) +   stat_summary(fun.data = mean_se,                 geom = \"crossbar\",                 color = \"black\",                 alpha = 0.2) +   stat_compare_means(method = \"t.test\",                       label = \"p.signif\",                      comparisons = list(c(\"setosa\", \"versicolor\"),                                         c(\"versicolor\", \"virginica\"),                                         c(\"setosa\", \"virginica\"))) ggplot(data = iris, mapping = aes(x = Species, y = Sepal.Length, color = Species, fill = Species)) +   geom_jitter(shape = 21, alpha = 0.4, size = 2) +   stat_summary(fun.data = mean_se,                 geom = \"crossbar\",                 color = \"black\",                 alpha = 0.2) +   stat_compare_means(method = \"t.test\",                       label = \"p.signif\",                      comparisons = list(c(\"setosa\", \"versicolor\"),                                         c(\"versicolor\", \"virginica\"),                                         c(\"setosa\", \"virginica\"))) +   scale_fill_brewer(palette = \"Dark2\", aesthetics = c(\"fill\", \"color\")) ggplot(data = iris, mapping = aes(x = Species, y = Sepal.Length, color = Species, fill = Species)) +   geom_jitter(shape = 21, alpha = 0.4, size = 2) +   stat_summary(fun.data = mean_se,                 geom = \"crossbar\",                 color = \"black\",                 alpha = 0.2) +   stat_compare_means(method = \"t.test\",                       label = \"p.signif\",                      comparisons = list(c(\"setosa\", \"versicolor\"),                                         c(\"versicolor\", \"virginica\"),                                         c(\"setosa\", \"virginica\"))) +   scale_fill_manual(values = c(\"setosa\" = \"red3\",                                 \"versicolor\" = \"green4\",                                 \"virginica\" = \"blue3\"),                      aesthetics = c(\"fill\", \"color\")) library(cowplot) ggplot(data = iris, mapping = aes(x = Species, y = Sepal.Length, color = Species, fill = Species)) +   geom_jitter(shape = 21, alpha = 0.4, size = 2) +   stat_summary(fun.data = mean_se,                 geom = \"crossbar\",                 color = \"black\",                 alpha = 0.2) +   stat_compare_means(method = \"t.test\",                       label = \"p.signif\",                      comparisons = list(c(\"setosa\", \"versicolor\"),                                         c(\"versicolor\", \"virginica\"),                                         c(\"setosa\", \"virginica\"))) +   scale_fill_manual(values = c(\"setosa\" = \"red3\",                                 \"versicolor\" = \"green4\",                                 \"virginica\" = \"blue3\"),                      aesthetics = c(\"fill\", \"color\")) +   theme_cowplot() +    theme(legend.position = \"none\")"},{"path":"/articles/week_3.html","id":"basic-statistical-testing","dir":"Articles","previous_headings":"","what":"Basic statistical testing","title":"Week 3:  Next Level R","text":"biostatistics course, probably want know perform things like t-tests wilcox tests data. R can perform large number statistical tests base functions: happening filtering dataset twice (group want compare) pulling value resulting dataframe numerical vector. fed t.test function. , base function painful type read. may wish use concise method: rstatix useful package extending base statistical functions R.","code":"t.test(x  = iris |>           filter(Species == \"setosa\") |>          pull(Sepal.Length),        y = iris |>          filter(Species == \"versicolor\") |>          pull(Sepal.Length),         var.equal = FALSE) #>  #>  Welch Two Sample t-test #>  #> data:  pull(filter(iris, Species == \"setosa\"), Sepal.Length) and pull(filter(iris, Species == \"versicolor\"), Sepal.Length) #> t = -10.521, df = 86.538, p-value < 2.2e-16 #> alternative hypothesis: true difference in means is not equal to 0 #> 95 percent confidence interval: #>  -1.1057074 -0.7542926 #> sample estimates: #> mean of x mean of y  #>     5.006     5.936 library(rstatix) # print out a table of descriptive values iris |>   group_by(Species) |>   get_summary_stats() #> # A tibble: 12 × 14 #>    Species  varia…¹     n   min   max median    q1    q3   iqr   mad  mean    sd #>    <fct>    <fct>   <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #>  1 setosa   Sepal.…    50   4.3   5.8   5     4.8   5.2  0.4   0.297 5.01  0.352 #>  2 setosa   Sepal.…    50   2.3   4.4   3.4   3.2   3.68 0.475 0.371 3.43  0.379 #>  3 setosa   Petal.…    50   1     1.9   1.5   1.4   1.58 0.175 0.148 1.46  0.174 #>  4 setosa   Petal.…    50   0.1   0.6   0.2   0.2   0.3  0.1   0     0.246 0.105 #>  5 versico… Sepal.…    50   4.9   7     5.9   5.6   6.3  0.7   0.519 5.94  0.516 #>  6 versico… Sepal.…    50   2     3.4   2.8   2.52  3    0.475 0.297 2.77  0.314 #>  7 versico… Petal.…    50   3     5.1   4.35  4     4.6  0.6   0.519 4.26  0.47  #>  8 versico… Petal.…    50   1     1.8   1.3   1.2   1.5  0.3   0.222 1.33  0.198 #>  9 virgini… Sepal.…    50   4.9   7.9   6.5   6.22  6.9  0.675 0.593 6.59  0.636 #> 10 virgini… Sepal.…    50   2.2   3.8   3     2.8   3.18 0.375 0.297 2.97  0.322 #> 11 virgini… Petal.…    50   4.5   6.9   5.55  5.1   5.88 0.775 0.667 5.55  0.552 #> 12 virgini… Petal.…    50   1.4   2.5   2     1.8   2.3  0.5   0.297 2.03  0.275 #> # … with 2 more variables: se <dbl>, ci <dbl>, and abbreviated variable name #> #   ¹​variable  # do the t-test iris |>   t_test(formula = Sepal.Length ~ Species) #> # A tibble: 3 × 10 #>   .y.          group1 group2    n1    n2 stati…¹    df        p    p.adj p.adj…² #> * <chr>        <chr>  <chr>  <int> <int>   <dbl> <dbl>    <dbl>    <dbl> <chr>   #> 1 Sepal.Length setosa versi…    50    50  -10.5   86.5 3.75e-17 7.5 e-17 ****    #> 2 Sepal.Length setosa virgi…    50    50  -15.4   76.5 3.97e-25 1.19e-24 ****    #> 3 Sepal.Length versi… virgi…    50    50   -5.63  94.0 1.87e- 7 1.87e- 7 ****    #> # … with abbreviated variable names ¹​statistic, ²​p.adj.signif"},{"path":"/articles/week_3.html","id":"exercises","dir":"Articles","previous_headings":"","what":"Exercises","title":"Week 3:  Next Level R","text":"practice writing simple functions read data work, plot ggplot perform statistical testing. Try using different geoms: geom_jitter() geom_col() useful. use readr::write_csv() write table statistical results cowplot::save_plot() save plot use purrr::map() apply function iteratively Extra credit: use cowplot::plot_grid() compose multiple plots figure","code":""},{"path":"/articles/week_6.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Week 6:  Packages","text":"lecture building R data packages. relatively advanced topic, think important can learned quickly. lecture assumes good working knowledge R computer file system. need expert R . want build data package? stages data pass : raw data: unchanged creation. Can entirely contained within R data package lightweight text file. Larger files archived shared network drive. processed data: data processed form can used plotting statistical analysis lines code second two computation time. analyzed data: final tables figures convey results experiment reader. data package meant hold processed data code used generate raw data. Since two things related, natural keep together digital file. Often data processing computer resource time-intensive don’t want repeat every time interact work. analyses (like single cell RNAseq dimension reduction) absolutely reproducible strictest sense saving processed data object means always starting place subsequent analysis. shouldn’t data package? decide . overhead (effort) making data package, won’t want save things can rapidly calculated derived data objects. Generally want data package GB size may need selective save. takes 3-4 seconds calculate data table figure, usually put data package. types things don’t include include: processed tabular data generating statistics plots single cell data objects (e.g. cellDataSet Seurat objects) qc files single cell analysis genomic ranges objects include: raw sequencing data, genomic features files, cell-barcode matrices subsets object already data package plots summary, benefits using data package : processed data linked code used generate processed data code single file can distributed used collaborators reviewers Data objects documented better chance recalling generated point future Data objects version-controlled easy change inadvertently. Data versions analysis code versions linked, can always recreate state project prior commit.","code":""},{"path":"/articles/week_6.html","id":"saving-r-objects","dir":"Articles","previous_headings":"","what":"Saving R objects","title":"Week 6:  Packages","text":"identified data object like put package, first need save disk .rda file. Usually going starting within analysis project. rules/best practices: create new directory called “data” hold data object save 1 object per file. R let save desirable way go. give file name object. use compression make file size small possible point just stop read data later needed using load(\"data/demo_iris_data.rda\"). better put package install package project reasons mentioned .","code":"# some demo data to save demo_iris_data <- iris  # make a data directory dir.create(\"data\")  # save the data as a .rda file save(demo_iris_data,       file = \"data/demo_iris_data.rda\",       compress = \"bzip2\")"},{"path":"/articles/week_6.html","id":"setting-up-the-package","dir":"Articles","previous_headings":"","what":"Setting up the package","title":"Week 6:  Packages","text":"First might want update ~/.Rprofile. add contact info package. use dedicated function blaseRtemplates set package project. regular project, want make readme set use git using initialization script: package like project additional requirements, like DESCRIPTION file. initialize_package function set . look done: important things note DESCRIPTION: file indicates R package. important line interact version. Every time make new version package (add, delete edit data), increment version number. Title description can edited provide general description purpose package critical. leave lines -. R/: directory contain R files. building package functions, go. data-package, create single R file called “data.R”. NAMESPACE: used data-packages. edit. README.md NEWS.md text files can edit described . files mostly boilerplate configuration files left alone.","code":"options(   usethis.full_name = \"Jane Doe\",   usethis.protocol  = \"ssh\",   usethis.description = list(     \"Authors@R\" = utils::person(         \"Jane\", \"Doe\",         email = \"jane@example.com\",         role = c(\"aut\", \"cre\"),         comment = c(ORCID = \"JANE'S-ORCID-ID\")     ),     Version = \"0.0.0.9000\"   ),   usethis.destdir = \"~/the/place/where/I/keep/my/R/projects\",   usethis.overwrite = TRUE ) blaseRtemplates::initialize_package(path = \"~/r_projects/workshop.data\") # make a software license  usethis::use_mit_license(\"<your name here>\")  # generate a readme file to explain your work  usethis::use_readme_md(open = FALSE)  # *** Only if developing a package ***  # uncomment and run to generate a news file to document updates.  usethis::use_news_md()  # set your default branch to \"main\" for git init  system(\"git config --global init.defaultBranch main\")  # initialize git  usethis::use_git()  # initialize github  usethis::use_github(private = TRUE)  ### Delete this file after initializing the project! ### . |-- blaser.park.datapkg.Rproj |-- data |   |-- cds_heme_combined.rda |   |-- cds_heme_combined_tm.csv |   `-- human_hsc_pseudobulk_res.rda |-- DESCRIPTION |-- inst |   |-- data-raw |   |   |-- git_commands.R |   |   |-- hsc_pseudobulk.R |   |   `-- reprocess_cds.R |   `-- extdata |       |-- cds_marrow_heme_models |       |   |-- file_index.rds |       |   |-- rdd_pca_transform_model.rds |       |   |-- rdd_umap_transform_model_annoy.idx |       |   |-- rdd_umap_transform_model.rds |       |   `-- rdd_umap_transform_model_umap.idx |       `-- gene_targets.csv |-- library_catalogs |   `-- blas02_blaser.park.datapkg.tsv |-- LICENSE |-- LICENSE.md |-- man |   |-- cds_heme_combined.Rd |   `-- human_hsc_pseudobulk_res.Rd |-- NAMESPACE |-- NEWS.md |-- R |   `-- data.R `-- README.md  8 directories, 23 files"},{"path":"/articles/week_6.html","id":"adding-data","dir":"Articles","previous_headings":"","what":"Adding data","title":"Week 6:  Packages","text":"simple. Just move data directory analysis project root directory new data package. editing existing package, just move new .rda files. can 1 data directory.","code":""},{"path":"/articles/week_6.html","id":"adding-data-processing-code","dir":"Articles","previous_headings":"","what":"Adding data-processing code","title":"Week 6:  Packages","text":"good keep processed data code used process . way problem can track easily. code go new directory called “data-raw”. unfortunate name data , code. need enclose directory called “inst”. Everything inst directory gets installed package.","code":""},{"path":"/articles/week_6.html","id":"option-include-raw-data","dir":"Articles","previous_headings":"Adding data-processing code","what":"Option: include raw data","title":"Week 6:  Packages","text":"want actually include raw data files package, make directory called “inst/extdata” put .","code":""},{"path":"/articles/week_6.html","id":"documenting-data","dir":"Articles","previous_headings":"","what":"Documenting data","title":"Week 6:  Packages","text":"Documenting data useful others. objects data folder need documentation entry. Documentation done structured text language called Roxygen easy work . easiest way start annotating simple data frame. sinew package help get format correct. Copy console just fill blanks. Usually important things clear, descriptive, unique title description line, describe data generated find code . example: standard data set distributed R, modifications. See data-raw/file_with_code_you_used.R. Sinew works data frames functions. want document types objects, can just copy/paste format.","code":"# install sinew if you don't have it sinew::makeOxygen(demo_iris_data)"},{"path":"/articles/week_6.html","id":"finish-up-the-data-package","dir":"Articles","previous_headings":"","what":"Finish up the data package","title":"Week 6:  Packages","text":"Make sure remember increment version data DESCRIPTION file. jot notes changed NEWS.md. Finally need tell R generate documentation files build binary data package. ’s . run last command, .tar.gz file generated directory enclosing data package code. can move wherever like. Better yet can provide file path R save binary package. usually save network storage. want sure increment version number time make changes don’t overwrite old versions data. always good able go back time needed. package can easily shared inside firewall local collaborators. external collaborators reviewers, can use things like Mendeley, Zotero, Dryad share large data packages. straightforward web interface option keep data private manuscript published.","code":"# generate the formatted documentation manuals devtools::document()  # optionally you can now commit and push to github using the terminal  # build the binary data package devtools::build()"},{"path":"/articles/week_6.html","id":"installing-the-data-package","dir":"Articles","previous_headings":"","what":"Installing the Data Package","title":"Week 6:  Packages","text":"packages make may little different typical R packages. functions somewhat unusual biggest difference size. working single cell data, likely size data package exceed R can handle normal mechanisms loading data. Instead use functions couple packages load data R session digital “pointer”. ask R reference particular data item, reside memory tiny digital address area hard drive. ask R reference data code, loaded memory used. additional advantage reducing memory requirements work. function go directory data lives, check latest version, install necessary. recommended way go almost always want latest version don’t want waste time installing necessary. function loads digital pointers R session. Check environment dropdown menu see .","code":"# install the data package blaseRtemplates::project_data(\"path/to/directory/containing/data\")"},{"path":"/articles/week_6.html","id":"exercises","dir":"Articles","previous_headings":"","what":"Exercises","title":"Week 6:  Packages","text":"now comfortable setting R project, analyzing data making figures manuscript presentation. Make R data package processed experimental data processing code used Save network (archival) drive Load data package back project using blaseRtemplates::project_data().","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Brad Blaser. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Blaser B (2023). datascience.curriculum: Data Science 2023. R package version 0.0.0.9008, https://blaserlab.github.io/datascience.curriculum/.","code":"@Manual{,   title = {datascience.curriculum: Data Science 2023},   author = {Brad Blaser},   year = {2023},   note = {R package version 0.0.0.9008},   url = {https://blaserlab.github.io/datascience.curriculum/}, }"},{"path":"/index.html","id":"welcome-to-the-computational-data-analysis-workshop","dir":"","previous_headings":"","what":"Welcome to the Computational Data Analysis Workshop","title":"Data Science 2023","text":"course designed help improve data management analysis skills. skills learn can used everything straightforward measurements biological data high-dimensional data like scRNA-seq. ever see figure made last year can’t remember made ? need write Data Sharing Plan NIH grant don’t know begin? Understanding principles cover help others reproduce extend work. 2023 course already started, can still join emailing bradley.blaser@osumc.edu.","code":""},{"path":"/index.html","id":"dates-for-the-2023-workshop","dir":"","previous_headings":"","what":"Dates for the 2023 workshop:","title":"Data Science 2023","text":"April 12 April 19 April 26 May 3 May 10 May 17 Wednesday mornings. Time 10-11 . Format Zoom Webinar.","code":""},{"path":"/index.html","id":"goals","dir":"","previous_headings":"","what":"Goals","title":"Data Science 2023","text":"goals workshop become comfortable R statistical computing language associated computational technology: Rstudio interacting R git version control github share work R package development keep code data separate organized","code":""},{"path":"/index.html","id":"specific-objectives","dir":"","previous_headings":"","what":"Specific Objectives","title":"Data Science 2023","text":"completed course able : properly format data efficient computation generate table descriptive statistics data typical biological experiment perform statistical testing appropriate generate publication-quality plots using ggplot perform basic analysis single cell RNA sequencing data compile processed source data R data package understand difference analysis code source data use basic version control functions track document changes analysis publish code reviewers can understand arrived results","code":""},{"path":"/index.html","id":"prerequisites","dir":"","previous_headings":"","what":"Prerequisites","title":"Data Science 2023","text":"course assumes prior knowledge R. designed biologists interest analyzing high-dimensional /computationally-intensive data. prerequisites basic understanding biological experimental design (controls, biological replicates, technical replicates, etc.) computer. first class make sure computer ready go. several computing options choose . can use personal computer. /software use course available Mac PC run directly machine. computer, just install programs . lab computer, admin install programs. may access lab server cloud service running Rstudio server. linux-based run everything using course. can register course Ohio Supercomputing Center. free use duration course. Access terminated end course. like use option, please email bradley.blaser@osumc.edu. send invitation. can use existing academic account Ohio Supercomputing center institution’s equivalent. cost tiny advantage computing environment may already familiar used/use work. R studio cloud (now Posit cloud) great option course academic research. subscription-based rates exorbitant compared pay supercomputing center academic institution. best computing option class wish use research projects. wish work local computer, links programs using: R (critical) Rstudio (critical) Git (recommended) Rtools (Windows ) Xcode command line tools (Mac ) Windows Mac users: see note installing Rtools Xcode. also register free github account. Choose name OK putting publication.","code":""},{"path":"/index.html","id":"course-structure","dir":"","previous_headings":"","what":"Course structure","title":"Data Science 2023","text":"workshop starts basics moves somewhat advanced topics. formal homework assignments, want comfortable topics previously presented time next class arrives. help read course material advance. things don’t make sense causing trouble first, encourage try figure using Google Stack Overflow. best way learn. questions problems encountered . Try running code class notes R script go lecture. expand horizon work data. Although try address conceptual questions, unable troubleshoot individual technical issues class. questions, comments problems getting things work, don’t get end class, can post issues . probably aren’t person question/problem, posting forum benefit others. lesson structured following way: 5 min people log enter pre-existing questions Q&. can questions prior week questions current day’s material. cover can lecture period. 45 min demonstrate concepts day’s lecture 10 min discussion additional Q&arise. Follow along workshop project github","code":""},{"path":"/index.html","id":"2023-curriculum","dir":"","previous_headings":"","what":"2023 Curriculum","title":"Data Science 2023","text":"course covers relatively wide range topics may intimidating new R users. Don’t worry don’t get first time . lectures recorded code notes published reference, can go back review may missed. first three lectures present basics using R. last three advanced. Even intermediate-level users pre-existing experience using R likely learn helpful information early lectures.","code":""},{"path":"/index.html","id":"week-1-setting-up-your-computing-environment---april-12-10-11-am-et","dir":"","previous_headings":"2023 Curriculum","what":"Week 1: Setting up your computing environment - April 12, 10-11 AM ET","title":"Data Science 2023","text":"Week 1 R script Week 1 notes Week 1 video R Rstudio blaseRtemplates Projects Packages Basic Git single user","code":""},{"path":"/index.html","id":"week-2-basics-of-working-with-data-in-r---april-19-10-11-am-et","dir":"","previous_headings":"2023 Curriculum","what":"Week 2: Basics of working with data in R - April 19, 10-11 AM ET","title":"Data Science 2023","text":"Week 2 R script Week 2 notes Week 2 video part 1 Week 2 video part 2 Review GIT File system basics Data Format Input Data Types Variable Assignment Data Structures Subsetting Data Data Operations Dplyr","code":""},{"path":"/index.html","id":"week-3-more-advanced-concepts-in-r---april-26-10-11-am-et","dir":"","previous_headings":"2023 Curriculum","what":"Week 3: More advanced concepts in R - April 26, 10-11 AM ET","title":"Data Science 2023","text":"Week 3 R script Week 3 notes Cheat sheets R color brewer R graphics cookbook Scope Writing Custom Functions Conditionals Map/Apply Plotting Statistical Testing","code":""},{"path":"/index.html","id":"week-4-blasertools-scrna-seq-tutorial-1---may-3-10-11-am-et","dir":"","previous_headings":"2023 Curriculum","what":"Week 4: blaseRtools scRNA-seq tutorial 1 - May 3, 10-11 AM ET","title":"Data Science 2023","text":"Week 4/5 R script Week 4 notes register email address download. Chromium controller Chromium X Data Management Preprocessing Data Cloud Loading Data cellDataSet QC Merging Dimension Reduction Batch Correction Clustering Gene Modules Label Transfer","code":""},{"path":"/index.html","id":"week-5-blasertools-scrna-seq-tutorial-2---may-10-10-11-am-et","dir":"","previous_headings":"2023 Curriculum","what":"Week 5: blaseRtools scRNA-seq tutorial 2 - May 10, 10-11 AM ET","title":"Data Science 2023","text":"Week 4/5 R script Week 5 notes UMAP Plots Gene Dotplots Pseudobulk Regression","code":""},{"path":"/index.html","id":"week-6-building-and-using-data-packages---may-17-10-11-am-et","dir":"","previous_headings":"2023 Curriculum","what":"Week 6: Building and using data packages - May 17, 10-11 AM ET","title":"Data Science 2023","text":"Week 6 R script Week 6 R notes Saving R Objects Setting Package Adding Data Adding Code Including Raw Data Documentation Finishing Loading Data Package","code":""},{"path":"/index.html","id":"course-evaluation","dir":"","previous_headings":"2023 Curriculum","what":"Course Evaluation","title":"Data Science 2023","text":"Thanks attending appreciate feedback things working. comments help improve course next year Please email bradley.blaser@osumc.edu","code":""},{"path":"/news/index.html","id":"datasciencecurriculum-0009008","dir":"Changelog","previous_headings":"","what":"datascience.curriculum 0.0.0.9008","title":"datascience.curriculum 0.0.0.9008","text":"updated week 1; reorganized git section","code":""},{"path":"/news/index.html","id":"datasciencecurriculum-0009006-7","dir":"Changelog","previous_headings":"","what":"datascience.curriculum 0.0.0.9006-7","title":"datascience.curriculum 0.0.0.9006-7","text":"updated week 2-6","code":""},{"path":"/news/index.html","id":"datasciencecurriculum-0009005","dir":"Changelog","previous_headings":"","what":"datascience.curriculum 0.0.0.9005","title":"datascience.curriculum 0.0.0.9005","text":"updated week 1","code":""},{"path":"/news/index.html","id":"datasciencecurriculum-0009003","dir":"Changelog","previous_headings":"","what":"datascience.curriculum 0.0.0.9003","title":"datascience.curriculum 0.0.0.9003","text":"updated links edits README","code":""},{"path":"/news/index.html","id":"datasciencecurriculum-0009003-1","dir":"Changelog","previous_headings":"","what":"datascience.curriculum 0.0.0.9003","title":"datascience.curriculum 0.0.0.9003","text":"added dependencies DESCRIPTION","code":""},{"path":"/news/index.html","id":"datasciencecurriculum-0009002","dir":"Changelog","previous_headings":"","what":"datascience.curriculum 0.0.0.9002","title":"datascience.curriculum 0.0.0.9002","text":"edited readme week1-6","code":""},{"path":"/news/index.html","id":"datasciencecurriculum-0009001","dir":"Changelog","previous_headings":"","what":"datascience.curriculum 0.0.0.9001","title":"datascience.curriculum 0.0.0.9001","text":"edited readme week1","code":""}]
